# [re:Ivent2018 Deep Dive on Amazon Aurora with PostgreSQL Compatibility](https://youtu.be/3PshvYmTv9M)

RDS PostgreSQLì˜ ê²½ìš°ì—ëŠ” PostgreSQLê°€ EC2 instanceì— ì˜¬ë¼ê°€ê³  EBS Volumeì´ ë¶™ì–´ ìˆëŠ” êµ¬ì¡°ì´ë‹¤.
Aurora PostgreSQLëŠ” Aurora Storageê°€ ì—°ê²°ë˜ì–´ ìˆë‹¤.

RDS PostgreSQLê³¼ Aurora PostgreSQLì€ ì•„ë˜ì™€ ê°™ì´ ë™ì¼í•œ extensions ì œê³µí•œë‹¤.
- Backup/Recovery - PITR
- HA & Durability
- IAM Auth
- Read replicas
- Cross region snapshots
- Scale Compute - Online scale storage

Cross Region replicationì´ë‘ Outbound logical replicationì€ í˜¸í™˜ë˜ë„ë¡ ì‘ì—…ì¤‘

## Log based storage

### PostgreSQL

ì—¬ë˜ ê°œì˜ commitì„ groupí•´ì„œ Log bufferì— í•œêº¼ë²ˆì— ë“¤ì–´ê°„ë‹¤.
Log bufferê°€ flushë˜ê¸° ì „ê¹Œì§€ëŠ” ë‹¤ë¥¸ queued workê°€ ê¸°ë‹¤ë ¤ì•¼í•œë‹¤.
log bufferê°€ flushë˜ì–´ì„œ storageì— ì €ì¥ì´ ë˜ê³ , acknowledgeë¥¼ í•˜ë©´ 
ì´ì œ log bufferì— ë‹¤ìŒ queue work ë“¤ì–´ê°ˆ ìˆ˜ ìˆê²Œ ëœë‹¤. 
ì´ê²Œ bottleneckì´ ëœë‹¤.

Queued Work \
Log Buffer \
Storage

group commitì€ ì—¬ëŸ¬ ê°œì˜ transactionë“¤ì„ batchë¡œ commití•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. 
commit delayë¼ëŠ” ì„¤ì •ì´ ìˆë‹¤. group commit leaderê°€ lockì„ acquireí•˜ê³  group followerê°€ commitì„ queueì— ì–¼ë§ˆë™ì•ˆ ìŒ“ì„ì§€ ê²°ì •í•˜ê²Œ ëœë‹¤.
ì´ë ‡ê²Œ ë‹¤ë¥¸ processê°€ WAL bufferì— commit recordë¥¼ ì¶”ê°€í•˜ê³  ì´ leaderê°€ flushí•´ì„œ WAL segmentì— ì €ì¥ë˜ê²Œ í•˜ëŠ” ê²ƒì´ë‹¤.
group commitì€ WAL segmentì— flushingí•˜ëŠ” ì‘ì—…ì˜ ë¶€í•˜ë¥¼ ëœì–´ì¤„ ìˆ˜ ìˆëŠ” ê²ƒ.

### Aurora
 
ë°˜ë©´ì— AuroraëŠ” log bufferê°€ ì—†ê³ , storageì— queued workê°€ ë°”ë¡œ ë“¤ì–´ê°„ë‹¤.
6ê°œì˜ storage nodeì—ì„œ 4ê°œê°€ acknowledgeë¥¼ í•˜ë©´ clientí•œí…Œ ì‘ë‹µ
ordered systemì´ë¼ì„œ ì´ì „ì˜ transactionì´ 4ê°œ ì´ìƒì˜ acknowledgeë¥¼ ëª»ë°›ìœ¼ë©´
ë‹¤ìŒ transactionì´ 4ê°œ ì´ìƒì„ ë°›ì•„ë„ ê¸°ë‹¤ë ¤ì•¼ ëœë‹¤.

#### 1. Auroraì—ëŠ” ê¸°ì¡´ PostgreSQLì²˜ëŸ¼ log bufferë•Œë¬¸ì— bottleneckì´ ìƒê¸´ì§€ ì•ŠëŠ”ë‹¤.

## Writing less

### PostgreSQL

PostgreSQLì—ëŠ” WAL(Write Ahead Logging)ì´ë¼ëŠ” ê²ƒì´ ì¡´ì¬í•œë‹¤. PostgreSQLëŠ” Shared bufferë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, tupleë“¤ì´ memoryì— ì €ì¥ë˜ì–´ ìˆë‹¤ê°€
Persistent storageì— ì£¼ê¸°ì ìœ¼ë¡œ flushing ëœë‹¤. ë”°ë¼ì„œ ì¤‘ê°„ì— ì„œë²„ê°€ ë‹¤ìš´ë˜ê±°ë‚˜ í•˜ë©´ memoryì— ìˆë˜ ì •ë³´ë“¤ì´ ë‚ ë¼ê°€ê²Œëœë‹¤. 
Durabilityë¥¼ ìœ„í•´ì„œ WALì— transaction historyê°€ ì €ì¥ëœë‹¤.

background processë¡œ checkpointí•˜ëŠ”ë°, ì¥ì• ê°€ ìƒê²¨ì„œ ë³µêµ¬ë¥¼ í•´ì•¼ë  ë•Œ ì‹œì‘í•´ì•¼ ë˜ëŠ” ì‹œì ì„ ê¸°ë¡í•˜ê²Œ ëœë‹¤. ê·¸ë¦¬ê³  shared bufferì— ìˆëŠ” dirty pagesê°€ flushingëœë‹¤.

ê·¼ë° OSë‹¨ì—ì„œ background writer processê°€ dirty pageë¥¼ ì“°ëŠ” ë„ì¤‘ì— ì—ëŸ¬ê°€ ë‚˜ì„œ corrupted pageê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤.
ì´ë ‡ê²Œ ë¬¸ì œê°€ ìƒê¸´ pageì—ë‹¤ê°€ WALì— ê¸°ë¡ëœ logë¥¼ ë‹¤ì‹œ replayí•  ìˆ˜ê°€ ì—†ë‹¤. ê·¸ë˜ì„œ Full page writesë¼ëŠ” ê¸°ëŠ¥ì´ ìˆëŠ”ë°,
checkpointí•˜ê³  ì²˜ìŒ ë°”ë€ŒëŠ” pageë¥¼ í†µì§¸ë¡œ ì €ì¥í•œë‹¤. ê·¸ë˜ì„œ ì´ë ‡ê²Œ corrupted pageê°€ ë°œìƒí•´ë„ checkpointì‹œì ìœ¼ë¡œ ì •ìƒì ì¸ pageì •ë³´ë¥¼ ì•„ë‹ˆê¹,
ì—¬ê¸°ì—ë‹¤ê°€ WALì— ê¸°ë¡ëœ logë¥¼ replayí•´ì„œ ë³µêµ¬í•˜ê²Œ ëœë‹¤.

PostgreSQLëŠ” default block size 8Kì´ê³  Linuxì—ì„œ 4Kë¼ì„œ ë­”ê°€ crashê°€ ë°œìƒí•´ì„œ PostgreSQLì˜ ì ˆë°˜ì˜ ë°ì´í„°ë§Œ Diskì— ì €ì¥ë  ìˆ˜ë„ ìˆë‹¤.
ì´ëŸ° ê²½ìš°ì— corrupted pageê°€ ìƒê¸°ëŠ”ê±°ê³  full page writesê¸°ëŠ¥ìœ¼ë¡œ ë³µêµ¬ê°€ ë  ìˆ˜ ìˆë‹¤.

### Aurora

Aurora read/write nodeê°€ updateë¥¼ í•˜ë©´ in-memory queueì— ë“¤ì–´ê°”ë‹¤ê°€ on diskì— ì €ì¥ë˜ëŠ” update queueë¡œ ì˜®ê²¨ê°€ê³  ì´ë•Œ
client acknowledgeë¥¼ í•œë‹¤. ì—¬ê¸°ê¹Œì§€ synchronousí•˜ê²Œ ë™ì‘í•˜ê³  ê·¸ë‹¤ìŒë¶€í„°ëŠ” backgroundë¡œ ë™ì‘í•œë‹¤.

acknowledgeí•˜ê³  ì´ì œ Data blockì— Coalesce(ìƒˆë¡œ ë“¤ì–´ì˜¨ ë°ì´í„°ë¥¼ í•œ blockìœ¼ë¡œ í•©ì¹˜ëŠ” ì‘ì—…ì¸ê²ƒ ê°™ë‹¤)í•˜ê³  Hog logë¡œë„ ë³´ë‚´ì ¸ì„œ
ë‹¤ë¥¸ nodeê°„ì— ìƒˆë¡œìš´ updateë¥¼ ì ìš©í•˜ê²Œ ëœë‹¤.

Read nodeëŠ” ì´ì œ Coalesceëœ data blockì—ì„œ ë°”ë¡œ ì½ê²Œ ëœë‹¤.

#### 2. AuroraëŠ” ê¸°ì¡´ PostgreSQLì²˜ëŸ¼ checkpoint, Full page writes ê¸°ëŠ¥ì´ í•„ìš”ì—†ë‹¤. ê·¸ë¦¬ê³  ê³„ì†í•´ì„œ ì´ë ‡ê²Œ data blockë¥¼ ì—…ë°ì´íŠ¸í•˜ê¸° ë•Œë¬¸ì— Long crash recoveryê°€ ì•„ë‹ˆë‹¤.  

## performance

### Insertë¥¼ 1ì´ˆì— 25,000ë²ˆ ì´ìƒí•˜ëŠ” benchmark

PostgreSQLì—ì„œëŠ” ì ì  ë°ì´í„°ê°€ ìŒ“ì´ë©´ì„œ checkpointì—ì„œ ê±´ë“œë¦¬ê²Œ ë˜ëŠ” blockë„ ë§ì•„ì§€ê³ , full page writesì—ì„œ writeí•˜ëŠ” pageì˜ í¬ê¸°ë„ ì»¤ì§€ë‹ˆê¹ ì„±ëŠ¥ì´ ê¸‰ê²©í•˜ê²Œ ë–¨ì–´ì§„ë‹¤.

### crash recovery

PostgreSQLì—ì„œ writeì´ ë§ì•„ì§€ë©´ Redo pointë¶€í„° recoveryí•´ì•¼ë˜ëŠ” ì–‘ë„ ë§ì•„ì§€ë‹ˆê¹ ëŠë ¤ì§€ê² ì§€

#### ìœ„ì—ì„œ ì„¤ëª…í•œ ê²ƒì²˜ëŸ¼ Auroraì—ì„œëŠ” full page writesê°€ í•„ìš”ì—†ê³  ì§€ì†ì ìœ¼ë¡œ recoveryë¥¼ í•˜ë‹ˆê¹, ì´ë¶€ë¶„ì—ì„œ í›¨ì”¬ ë›°ì–´ë‚œ performanceë¥¼ ë³´ì¼ ìˆ˜ ìˆë‹¤.

## Vacuum

PostgreSQLì—ì„œ Vacuum processë¡œ dead tuple(Deleteëœ)ì€ table fileì˜ pageì—ì„œ ì œê±°ëœë‹¤. Visibility mapì€ ì´ Vacuum proccessë¥¼ ê°œì„ í•œ ë°©ë²•ì´ë‹¤.

auroraì—ì„œ writeì„±ëŠ¥ì„ 2~3ë°° í–¥ìƒì‹œì¼°ë‹¤ê³  í–ˆëŠ”ë°, Vaccumì€ ê·¸ëŒ€ë¡œë©´ ì´ê±´ Disasterë¼ê³  ë§í•œë‹¤. ê·¸ë˜ì„œ Auroraì—ì„œëŠ”
Vacuumí•´ì•¼í•  block addressë¥¼ ê°€ì ¸ì™€ì„œ batchë¡œ Vacuumí•œë‹¤.

#### 3. Auroraì—ì„œ Vacuum ì„±ëŠ¥ë„ í–¥ìƒì‹œì¼°ë‹¤.

## Caching

OSë‘ PostgreSQL processê°€ ì“°ëŠ” ë©”ëª¨ë¦¬ê°€ ìˆê³ , ì´ì œ shared bufferì˜ì—­ê³¼ Linuxì˜ page cachesì˜ì—­ì´ ìˆëŠ”ë°, 
shared bufferì™€ page cacheì˜ì—­ì— ì¤‘ë³µë˜ëŠ” bufferê°€ ìƒê¸´ë‹¤. Shared buffer ì˜ì—­ì´ í¬ë©´ Transaction per secondê°€ í–¥ìƒë˜ëŠ”ë°,
PostgreSQLì—ì„œë„ 75% shared bufferë¥¼ ì‚¬ìš©í•˜ë©´ Auroraì˜ 75% cacheë‘ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤. ë¬¸ì œëŠ” PogreSQL í”„ë¡œì„¸ìŠ¤ê°€ ì£½ìœ¼ë©´ ì´ì œ
shared bufferëŠ” ë‚ ë¼ê°€ì§€ë§Œ page cacheë¶€ë¶„ì„ ì‚´ì•„ë‚¨ê²Œ ëœë‹¤. í•˜ì§€ë§Œ shared bufferë§Œ 75%ë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤ ë‚ ë¼ê°€ê²Œ ë˜ëŠ”ë°,
AuroraëŠ” PostgreSQL í”„ë¡œì„¸ìŠ¤ì™€ ë…ë¦½ì ìœ¼ë¡œ ì‚´ì•„ë‚¨ëŠ” shared bufferë¥¼ êµ¬ì„±í•˜ê³  ìˆë‹¤.

#### 4. Auroraì—ì„œëŠ” 75% shared bufferë¥¼ ì‚¬ìš©í•˜ê³  PSQL processê°€ ì£½ì–´ë„ ë³„ë„ë¡œ ì‚´ì•„ë‚¨ëŠ” cacheì´ë‹¤.

## Replica

RDSì—ì„œ replicaëŠ” RW nodeì—ì„œ updateê°€ ë°œìƒí•˜ë©´ RW nodeì— ìˆëŠ” EBSì— ì €ì¥í•˜ê³  Read Nodeì—ê²Œ asyncí•˜ê²Œ ì „ë‹¬í•˜ë©´,
Read Nodeì˜ EBSì— Updateí•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•˜ê²Œ ëœë‹¤.

í•˜ì§€ë§Œ Auroraì—ì„œëŠ” Aurora Storage layerë¥¼ ê³µìœ í•˜ê³ , RW nodeì—ì„œ asyncí•˜ê²Œ Read nodeì— ì „ë‹¬í•˜ë©´ Read Nodeì˜ memoryì— ìˆëŠ” ì •ë³´ë§Œ updateí•œë‹¤.

RW Nodeì— ë„¤ê°€ì§€ì˜ tableì´ ìˆê³ , ë‹¤ ìˆ˜ì •ëœë‹¤. ê·¸ë¦¬ê³  Read only Nodeê°€ ìˆë‹¤.
Read only nodeì—ì„œ ì´ë¯¸ table Aë¥¼ readí–ˆë‹¤ê³  í•˜ë©´ memoryì— table Aì˜ ì •ë³´ê°€ ìˆë‹¤. ê·¼ë° RDSì—ì„œ async replicationì„ í•˜ë©´ ìˆ˜ì •ëœ ëª¨ë“  tableì´ memoryì— ì ìš©ë˜ê²Œ ëœë‹¤.
í•˜ì§€ë§Œ, Auroraì—ì„œëŠ” table Aë§Œ memoryì—ì„œ updateê°€ ì¼ì–´ë‚œë‹¤.

ê·¸ë˜ì„œ performance benchmarkì—ì„œ Read only nodeê°€ readë¥¼ ê³„ì† í•˜ê³  ìˆì„ ë•Œ, RW nodeì— ëŒ€ëŸ‰ì˜ updateê°€ ë°œìƒí•˜ê²Œ ì‹œí‚¤ë©´,
replication delayê°€ RDSì—ì„œ ê¸‰ê²©í•˜ê²Œ ëŠ˜ì–´ë‚˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤.

#### 5. Auroraì—ì„œëŠ” replicaê°€ read-onlyì˜ memoryë§Œ updateëœë‹¤.

## Cluster Cache Management Feature

Failoverê°€ ë°œìƒí•´ì„œ Read-onlyê°€ RW nodeì—­í• ì„ ë„˜ê²¨ë°›ëŠ”ë‹¤. ê·¼ë° failoverë˜ì„œ Read-only nodeê°€ writeë¥¼ ë‹¤ì‹œ ì‹œì‘í•˜ëŠ”ë°ëŠ”
DNSê¹Œì§€ í¬í•¨í•´ì„œ ëª‡ì‹­ì´ˆë©´ ë˜ëŠ”ë°, cacheê°€ warm upì´ ì•ˆë˜ì„œ ë†’ì€ TPSë¡œ ë‹¤ì‹œ ì˜¬ë¼ê°€ëŠ”ë° í›¨ì”¬ ë” ë§ì€ ì‹œê°„ì´ ê±¸ë¦°ë‹¤.
 
cluster ë‹¨ìœ„ì˜ parameterì—ì„œ apg_ccm_enabledë¥¼ oní•´ì£¼ê³ , priorityë¥¼ ì„¤ì •í•´ì„œ read nodeì˜ cacheìƒí™©ì„ RW nodeì™€ ë¹„ìŠ·í•˜ê²Œ ê°€ì ¸ê°€ë„ë¡ í•  ìˆ˜ ìˆë‹¤.

## Fast Clone

Cloneì„ ë§Œë“¤ì–´ì„œ Primary storageì˜ dataë¥¼ ê°€ë¦¬í‚¤ê¸°ë§Œ í•  ìˆ˜ ìˆë‹¤.
ê°€ë¦¬í‚¤ëŠ” primary storageì˜ dataê°€ updateë˜ë©´ cloneì— ë°˜ì˜ë˜ê³ , ì¶”ê°€ë˜ëŠ” dataëŠ” ë°˜ì˜ì•ˆëœë‹¤.
ê·¸ë¦¬ê³  cloneì—ì„œ ìƒˆë¡œ ì €ì¥ë˜ê±°ë‚˜ update primaryì— ë°˜ì˜ì´ ì•ˆë˜ê³ .

ğŸ¤” í…ŒìŠ¤íŠ¸í•  ë•Œ Fast Cloneì„ ì‚¬ìš©í•´ë³¼ ìˆ˜ ìˆì„ê¹Œ?

## Logical replication support
- V10ì—ì„œëŠ” publish/subscribe to another PostgreSQL instance

## Cross region replication

## Query Plan Management

# [Deep Dive on Amazon Aurora with MySQL Compatibility](https://youtu.be/U42mC_iKSBg)

## Traditional database architecture

SQL
Transactions
Caching
Logging
Local storage

local storage => network storage

Traditional Distributed Database stack

Sharding

Shared nothing

Shared Disk

Aurora distributed architecture

- Push Log applicator to Storage
=> contruct pages from the log themselves

traditional engineì—ì„œëŠ” logë‘ pageë¥¼ writeí•´ì•¼ í•˜ëŠ”ë°,
aurora only write log => less I/O, no checkpoint, cache eviction, background flushing

- 4/6 Write Quorum & Locak tracking

when storage receive write they accept. no voting involved

write performance

read scale out

AZ + 1 failure tolerance

Instant database redo recovery

# log applicator

masterì— transactionì´ ì‹œì‘ë˜ë©´,
6ê°œì˜ storageì— ì „ë‹¬ë˜ê³  readerì—ê²Œë„ asyncí•˜ê²Œ replication ì „ë‹¬

mysqlì—ì„œ binlogë¡œ ë³€ê²½ëœê²Œ replicaì— ì „ë‹¬ë˜ì„œ replica data volumeì—
ì €ì¥í•˜ê¸° ë•Œë¬¸ì— wirte I/Oê°€ ë°œìƒí•œë‹¤.

auroraëŠ” shared storageë¥¼ ê·¸ëƒ¥ readerê°€ ì½ê¸°ë§Œ í•˜ë©´ ë˜ë‹ˆê¹ write I/Oê°€ ë°œìƒì•ˆí•˜ëŠ”

ì „í†µì ì¸ mysqlì—ì„œ

accumulate the set of log records => log buffer=> group commit
as soon as flushed you acknowledge back to client

- don't have checkpoints because construct page from the logs
- out of order flush
- no have heavy weight consensus

mysql thread model => connectionë‹¹ threadìƒì„±

AuroraëŠ” thread pool with event based eople and latch free task queue

Mysql lock manager

any update will lock the whole lock table

checkpointë¥¼ í¬ê²Œí•˜ë©´ Write/sëŠ” ì¢‹ì•„ì§€ëŠ”ë° recovery timeì´ ê¸¸ì–´ì§„ë‹¤.

## Exsiting Multi-master solutions

Distributed lock manager

Heavyweight synchronization: pessimistic and negative scaling

Global ordering with read-write set

Global entity: scaling bottleneck

paxos leader with 2PC

Heavy weight consensus protocol : Hot partitions and struggle with cross parition queries

CockroachDBê°€ ì—¬ê¸°ì— í¬í•¨ë˜ëŠ”êµ¬ë‚˜.